{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "import re\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_games_list(filename='corpus.txt', verbose = False):\n",
    "    '''\n",
    "    in: filename, the corpus\n",
    "    out: list of list of events in each game\n",
    "    '''\n",
    "    if verbose:\n",
    "        print('Reading corpus')\n",
    "    return [game.split() for game in open(filename,'r').readlines()]\n",
    "    \n",
    "def strip_aZ(games_list):\n",
    "    '''\n",
    "    in: list of lists of games\n",
    "    out: stripped to just ^a-zA-Z\n",
    "    '''\n",
    "    print('Stripping games_list of non-[^a-zA-Z] characters')\n",
    "    regex = re.compile('[^a-zA-Z]')\n",
    "    games_list = [[regex.sub('',event) for event in game] for game in games_list]\n",
    "    #print(games_list[:3][:5])\n",
    "    return games_list\n",
    "    \n",
    "    \n",
    "def make_vocabulary(games_list, verbose=False):\n",
    "    '''\n",
    "    in: list of lists of games\n",
    "    out: \n",
    "        vocabulary, the number of distinct events\n",
    "            and\n",
    "        event_2_ind, a lookup dictionary for the index of each event\n",
    "    '''\n",
    "    if verbose:\n",
    "        print('Constructing vocabular and event2id dictionary')\n",
    "    \n",
    "    #full events list to make vocabulary and ids\n",
    "    events = flatten_games_to_events(games_list)\n",
    "    #select distinct\n",
    "    distinct_events = list(set(events))\n",
    "    vocabulary = len(distinct_events)\n",
    "    #make id dictionary\n",
    "    event_2_id = {}\n",
    "    for event in distinct_events:\n",
    "        event_2_id[event] = distinct_events.index(event)\n",
    "    id_2_event = dict(zip(event_2_id.values(), event_2_id.keys()))\n",
    "    return vocabulary, event_2_id, id_2_event\n",
    "   \n",
    "def games_list_to_ids(games_list, event_2_id, verbose=False):\n",
    "    '''\n",
    "    in: games_list, list of lists of events in string format\n",
    "        event_2_id, id dictionary constructed from full vocabulary\n",
    "    out: \n",
    "        games_list, list of lists of events in id format\n",
    "    '''\n",
    "    if verbose:\n",
    "        print('Encoding a list of games by event id')\n",
    "    return [[event_2_id[event] for event in game] for game in games_list]\n",
    "\n",
    "def train_test_split_games_list(games_list, train_frac = .8, verbose=False):\n",
    "    if verbose:\n",
    "        print(f'Making train test split. train_frac = {train_frac}')\n",
    "    split_ind = int(len(games_list)*train_frac)\n",
    "    train = games_list[:split_ind]\n",
    "    test = games_list[split_ind:]\n",
    "    return train, test\n",
    "\n",
    "def flatten_games_to_events(games_list): \n",
    "    return [event for game in games_list\n",
    "                     for event in game]\n",
    "\n",
    "def load_data(filename):\n",
    "    '''\n",
    "    in: filename, a .txt file whose lines are nhl games where events\n",
    "    are represented by strings separated by spaces\n",
    "    '''\n",
    "    games_list = load_games_list('corpus.txt', \n",
    "                                 verbose=True)[:200]\n",
    "    \n",
    "    ###This is to make things fast for now\n",
    "    games_list = strip_aZ(games_list)\n",
    "    \n",
    "    #building word to index dictionary and vocabulary\n",
    "    vocabulary, event_2_id, id_2_event = make_vocabulary(games_list, \n",
    "                                                         verbose=True)\n",
    "    \n",
    "    #convert to ids\n",
    "    games_list = games_list_to_ids(games_list, \n",
    "                                   event_2_id, \n",
    "                                   verbose=True)\n",
    "    \n",
    "    #train test split\n",
    "    train_data, test_data = train_test_split_games_list(games_list, \n",
    "                                                        verbose=True)\n",
    "    train_data = flatten_games_to_events(train_data)\n",
    "    test_data = flatten_games_to_events(test_data)\n",
    "    valid_data = None\n",
    "    \n",
    "    reversed_dictionary = None\n",
    "    \n",
    "    return (\n",
    "            train_data, \n",
    "            valid_data, \n",
    "            test_data, \n",
    "            vocabulary, \n",
    "            reversed_dictionary, \n",
    "            event_2_id,\n",
    "            id_2_event\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KerasBatchGenerator(object):\n",
    "    '''\n",
    "    generates batches for Keras to train neural networks \n",
    "    should I grab the batches randomly?\n",
    "    '''\n",
    "    def __init__(self, data, num_steps, batch_size, vocabulary, skip_step=5):\n",
    "        self.data = data\n",
    "        self.num_steps = num_steps\n",
    "        self.batch_size = batch_size\n",
    "        self.vocabulary = vocabulary\n",
    "        self.current_idx = 0\n",
    "        self.skip_step = skip_step\n",
    "        \n",
    "    def generate(self):\n",
    "        #input is just the number of steps in each in, and the batch size\n",
    "        x = np.zeros((self.batch_size, \n",
    "                      self.num_steps))\n",
    "        #output will be one-hots of dimension vocabulary\n",
    "        y = np.zeros((self.batch_size, \n",
    "                      self.num_steps, \n",
    "                      self.vocabulary))\n",
    "        while True:#never terminate\n",
    "            for i in range(self.batch_size):\n",
    "                #if I would run over the edge, reset idx\n",
    "                if self.current_idx + self.num_steps >= len(self.data):\n",
    "                    self.current_idx = 0\n",
    "                x[i,:] = self.data[self.current_idx:self.current_idx + self.num_steps]\n",
    "                temp_y = self.data[self.current_idx + 1:self.current_idx + self.num_steps+1]\n",
    "                #make the one-hots for the y training data\n",
    "                y[i,:,:] = to_categorical(temp_y, \n",
    "                                          num_classes=self.vocabulary)\n",
    "                self.current_idx += self.skip_step\n",
    "            yield x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading corpus\n",
      "Stripping games_list of non-[^a-zA-Z] characters\n",
      "Constructing vocabular and event2id dictionary\n",
      "Encoding a list of games by event id\n",
      "Making train test split. train_frac = 0.8\n"
     ]
    }
   ],
   "source": [
    "train_data, valid_data, test_data, vocabulary, reversed_dictionary, event_2_id, id_2_event = load_data('corpus.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
